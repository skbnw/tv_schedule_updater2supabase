"""
å‡ºæ¼”è€…æƒ…å ±è£œå®Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ v1.1
- å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å–å¾—ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå€‹åˆ¥ãƒã‚§ãƒƒã‚¯ã‚’å‰Šæ¸›ï¼‰
- æ—¥ä»˜ã”ã¨ã«å‡¦ç†ã‚’åˆ†å‰²å¯èƒ½
- ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åˆ¶é™ã—ã¦ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å›é¿
"""
import os
import json
from supabase import create_client, Client
from datetime import datetime, timedelta

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
def get_env(key, default=None):
    v = os.environ.get(key)
    if v is None:
        return default
    return v

SUPABASE_URL = get_env("SUPABASE_URL")
SUPABASE_KEY = get_env("SUPABASE_KEY")

# Supabaseæ¥ç¶š
table_name = "program_talent_appearances"
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# JSONãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å
STORAGE_BUCKET = "json-backups"

# 1å›ã®ãƒãƒƒãƒã§å‡¦ç†ã™ã‚‹æœ€å¤§ä»¶æ•°ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå›é¿ã®ãŸã‚å‰Šæ¸›ï¼‰
MAX_PROGRAMS = int(get_env("MAX_PROGRAMS", "5000"))

# å‡¦ç†å¯¾è±¡æ—¥ä»˜ç¯„å›²ï¼ˆç’°å¢ƒå¤‰æ•°ã§æŒ‡å®šå¯èƒ½ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯éå»7æ—¥é–“ï¼‰
TARGET_DAYS_BACK = int(get_env("TARGET_DAYS_BACK", "7"))


def get_all_json_files(target_dates=None):
    """
    json-backupsã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å†…ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
    target_datesãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ãã®æ—¥ä»˜ã®ã¿ã€Noneã®å ´åˆã¯å…¨ãƒ•ã‚¡ã‚¤ãƒ«
    """
    files = []
    
    # ãƒ«ãƒ¼ãƒˆã®æ—¥ä»˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§
    date_dirs = supabase.storage.from_(STORAGE_BUCKET).list(path="")
    
    # å¯¾è±¡æ—¥ä»˜ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if target_dates:
        target_dates_set = set(target_dates)
    
    for date_dir in date_dirs:
        if date_dir.get('name'):
            date_path = date_dir['name']
            
            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if target_dates and date_path not in target_dates_set:
                continue
            
            # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§
            try:
                channel_dirs = supabase.storage.from_(STORAGE_BUCKET).list(path=date_path)
                for ch_dir in channel_dirs:
                    if ch_dir.get('name'):
                        ch_path = f"{date_path}/{ch_dir['name']}"
                        # JSONãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
                        try:
                            json_files = supabase.storage.from_(STORAGE_BUCKET).list(path=ch_path)
                            for jf in json_files:
                                if jf.get('name', '').endswith('.json'):
                                    files.append(f"{ch_path}/{jf['name']}")
                        except Exception as e:
                            print(f"âš ï¸ {ch_path}ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            except Exception as e:
                print(f"âš ï¸ {date_path}ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    return files


def get_existing_pairs_batch(event_ids):
    """
    æ—¢å­˜ã®program_event_id + talent_idãƒšã‚¢ã‚’ä¸€æ‹¬å–å¾—
    """
    existing_pairs = set()
    
    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åˆ¶é™ï¼ˆSupabaseã®åˆ¶é™ã‚’è€ƒæ…®ï¼‰
    batch_size = 100
    for i in range(0, len(event_ids), batch_size):
        batch = event_ids[i:i+batch_size]
        try:
            result = supabase.table(table_name).select("program_event_id,talent_id").in_("program_event_id", batch).execute()
            for row in result.data:
                existing_pairs.add((row['program_event_id'], row['talent_id']))
        except Exception as e:
            print(f"âš ï¸ æ—¢å­˜ãƒšã‚¢å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    return existing_pairs


def supplement_appearances_from_json(target_dates=None):
    """
    å‡ºæ¼”è€…æƒ…å ±ã‚’è£œå®Œã™ã‚‹ãƒ¡ã‚¤ãƒ³å‡¦ç†
    target_dates: å‡¦ç†å¯¾è±¡ã®æ—¥ä»˜ãƒªã‚¹ãƒˆï¼ˆYYYY-MM-DDå½¢å¼ï¼‰ã€Noneã®å ´åˆã¯å…¨ãƒ•ã‚¡ã‚¤ãƒ«
    """
    print("\n=== JSON performersè£œå®Œãƒãƒƒãƒ é–‹å§‹ ===")
    
    # å¯¾è±¡æ—¥ä»˜ã‚’æ±ºå®š
    if target_dates is None:
        # éå»Næ—¥é–“ã®æ—¥ä»˜ã‚’ç”Ÿæˆ
        today = datetime.now().date()
        target_dates = [(today - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(TARGET_DAYS_BACK)]
        print(f"ğŸ“… å¯¾è±¡æœŸé–“: {target_dates[-1]} ã€œ {target_dates[0]} ({len(target_dates)}æ—¥)")
    else:
        print(f"ğŸ“… å¯¾è±¡æ—¥ä»˜: {', '.join(target_dates)}")
    
    files = get_all_json_files(target_dates)
    print(f"ğŸ“‹ JSONãƒ•ã‚¡ã‚¤ãƒ«ç·æ•°: {len(files)}ä»¶")
    
    if not files:
        print("âš ï¸ å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # ã¾ãšå…¨event_idã‚’åé›†ã—ã¦æ—¢å­˜ãƒšã‚¢ã‚’ä¸€æ‹¬å–å¾—
    print("ğŸ” æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªä¸­...")
    all_event_ids = []
    file_data_map = {}
    
    for file_path in files[:MAX_PROGRAMS]:  # æœ€å¤§ä»¶æ•°ã¾ã§
        try:
            res = supabase.storage.from_(STORAGE_BUCKET).download(file_path)
            data = json.loads(res.decode('utf-8'))
            event_id = data.get('event_id')
            if event_id:
                all_event_ids.append(event_id)
                file_data_map[file_path] = data
        except Exception as e:
            print(f"âš ï¸ JSONèª­è¾¼ã‚¨ãƒ©ãƒ¼: {file_path} {e}")
    
    print(f"ğŸ“Š åé›†ã—ãŸevent_id: {len(all_event_ids)}ä»¶")
    
    # æ—¢å­˜ãƒšã‚¢ã‚’ä¸€æ‹¬å–å¾—
    existing_pairs = get_existing_pairs_batch(list(set(all_event_ids)))
    print(f"âœ… æ—¢å­˜ãƒšã‚¢æ•°: {len(existing_pairs)}ä»¶")
    
    # å‡¦ç†é–‹å§‹
    supplement_count = 0
    skip_count = 0
    error_count = 0
    processed_count = 0
    
    # å‡¦ç†å¯¾è±¡ã®ã‚¿ãƒ¬ãƒ³ãƒˆIDã‚’åé›†
    print("ğŸ” å‡¦ç†å¯¾è±¡ã‚¿ãƒ¬ãƒ³ãƒˆIDã‚’åé›†ä¸­...")
    target_talent_ids = set()
    for data in file_data_map.values():
        performers = data.get('performers', [])
        for performer in performers:
            talent_id = performer.get('talent_id')
            if talent_id:
                target_talent_ids.add(talent_id)
    
    print(f"ğŸ“Š å‡¦ç†å¯¾è±¡ã‚¿ãƒ¬ãƒ³ãƒˆID: {len(target_talent_ids)}ä»¶")
    
    # æ—¢å­˜ã‚¿ãƒ¬ãƒ³ãƒˆã‚’ä¸€æ‹¬å–å¾—ï¼ˆå‡¦ç†å¯¾è±¡ã®ã¿ï¼‰
    existing_talents = set()
    if target_talent_ids:
        try:
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åˆ¶é™
            batch_size = 100
            talent_ids_list = list(target_talent_ids)
            for i in range(0, len(talent_ids_list), batch_size):
                batch = talent_ids_list[i:i+batch_size]
                result = supabase.table('talents').select('talent_id').in_('talent_id', batch).execute()
                if result.data:
                    existing_talents.update([t['talent_id'] for t in result.data])
            print(f"âœ… æ—¢å­˜ã‚¿ãƒ¬ãƒ³ãƒˆæ•°: {len(existing_talents)}ä»¶")
        except Exception as e:
            print(f"âš ï¸ æ—¢å­˜ã‚¿ãƒ¬ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒãƒƒãƒæŒ¿å…¥ç”¨ã®ãƒªã‚¹ãƒˆ
    talents_to_insert = []
    appearances_to_insert = []
    batch_size = 100
    
    for idx, (file_path, data) in enumerate(file_data_map.items()):
        try:
            event_id = data.get('event_id')
            performers = data.get('performers', [])
            
            if not event_id or not performers:
                skip_count += 1
                continue
            
            for performer in performers:
                talent_id = performer.get('talent_id')
                if not talent_id:
                    continue
                
                pair_key = (event_id, talent_id)
                
                # æ—¢å­˜ãƒšã‚¢ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if pair_key in existing_pairs:
                    continue
                
                # talentsãƒ†ãƒ¼ãƒ–ãƒ«ã«è¿½åŠ ï¼ˆãªã‘ã‚Œã°ï¼‰
                if talent_id not in existing_talents:
                    talents_to_insert.append({
                        'talent_id': talent_id,
                        'name': performer.get('name', ''),
                        'link': performer.get('link', '')
                    })
                    existing_talents.add(talent_id)
                
                # program_talent_appearancesã«è¿½åŠ 
                appearances_to_insert.append({
                    "program_event_id": event_id,
                    "talent_id": talent_id
                })
                existing_pairs.add(pair_key)  # é‡è¤‡é˜²æ­¢
                
                # ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰ä¸€æ‹¬æŒ¿å…¥
                if len(appearances_to_insert) >= batch_size:
                    # talentsã‚’ä¸€æ‹¬æŒ¿å…¥
                    if talents_to_insert:
                        try:
                            supabase.table('talents').insert(talents_to_insert).execute()
                            print(f"âœ… ã‚¿ãƒ¬ãƒ³ãƒˆä¸€æ‹¬ç™»éŒ²: {len(talents_to_insert)}ä»¶")
                            talents_to_insert = []
                        except Exception as e:
                            print(f"âš ï¸ ã‚¿ãƒ¬ãƒ³ãƒˆä¸€æ‹¬ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
                    
                    # appearancesã‚’ä¸€æ‹¬æŒ¿å…¥
                    try:
                        supabase.table(table_name).insert(appearances_to_insert).execute()
                        supplement_count += len(appearances_to_insert)
                        print(f"âœ… å‡ºæ¼”æƒ…å ±ä¸€æ‹¬ç™»éŒ²: {len(appearances_to_insert)}ä»¶ (ç´¯è¨ˆ: {supplement_count}ä»¶)")
                        appearances_to_insert = []
                    except Exception as e:
                        print(f"âš ï¸ å‡ºæ¼”æƒ…å ±ä¸€æ‹¬ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
                        error_count += len(appearances_to_insert)
                        appearances_to_insert = []
            
            processed_count += 1
            if (idx + 1) % 100 == 0:
                print(f"ğŸ“Š é€²æ—: {idx + 1}/{len(file_data_map)}ä»¶å‡¦ç†æ¸ˆã¿")
                
        except Exception as e:
            print(f"âŒ JSONå‡¦ç†ã‚¨ãƒ©ãƒ¼: {file_path} {e}")
            error_count += 1
        
        if processed_count >= MAX_PROGRAMS:
            print(f"âš ï¸ æœ€å¤§å‡¦ç†ä»¶æ•°({MAX_PROGRAMS})ã«åˆ°é”ã—ãŸãŸã‚ä¸­æ–­")
            break
    
    # æ®‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
    if talents_to_insert:
        try:
            supabase.table('talents').insert(talents_to_insert).execute()
            print(f"âœ… ã‚¿ãƒ¬ãƒ³ãƒˆæœ€çµ‚ç™»éŒ²: {len(talents_to_insert)}ä»¶")
        except Exception as e:
            print(f"âš ï¸ ã‚¿ãƒ¬ãƒ³ãƒˆæœ€çµ‚ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    
    if appearances_to_insert:
        try:
            supabase.table(table_name).insert(appearances_to_insert).execute()
            supplement_count += len(appearances_to_insert)
            print(f"âœ… å‡ºæ¼”æƒ…å ±æœ€çµ‚ç™»éŒ²: {len(appearances_to_insert)}ä»¶")
        except Exception as e:
            print(f"âš ï¸ å‡ºæ¼”æƒ…å ±æœ€çµ‚ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
            error_count += len(appearances_to_insert)
    
    print(f"\n=== JSON performersè£œå®Œãƒãƒƒãƒ çµ‚äº† ===")
    print(f"  âœ… è£œå®Œç™»éŒ²: {supplement_count}ä»¶")
    print(f"  â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {skip_count}ä»¶ (å‡ºæ¼”è€…ãªã—ç­‰)")
    print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
    print(f"  ğŸ“Š å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {processed_count}ä»¶")

if __name__ == "__main__":
    # ç’°å¢ƒå¤‰æ•°ã§ç‰¹å®šæ—¥ä»˜ã‚’æŒ‡å®šå¯èƒ½ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
    target_dates_env = get_env("TARGET_DATES")
    target_dates = None
    if target_dates_env:
        target_dates = [d.strip() for d in target_dates_env.split(",")]
    
    supplement_appearances_from_json(target_dates) 