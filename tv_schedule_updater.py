import os
import time
import random
import requests
import json
import shutil
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from supabase import create_client, Client


# é€£æºã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®š
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")

# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡
TARGET_CHANNELS = ["NHKG-TKY", "NHKE-TKY", "NTV-TKY", "TV-ASAHI-TKY", "TBS-TKY", "TV-TOKYO-TKY", "FUJI-TV-TKY"]
TARGET_DAYS = 2 # å–å¾—æ—¥æ•°
ROTATION_DAYS = 120 # ãƒ‡ãƒ¼ã‚¿ã®ä¿æŒæ—¥æ•°

CHANNEL_MAPPING = {
    # æ±äº¬ åœ°ä¸Šæ³¢
    "NHKG-TKY": "NHKç·åˆ", "NHKE-TKY": "NHKEãƒ†ãƒ¬", "NTV-TKY": "æ—¥ãƒ†ãƒ¬",
    "TV-ASAHI-TKY": "ãƒ†ãƒ¬ãƒ“æœæ—¥", "TBS-TKY": "TBS", "TV-TOKYO-TKY": "ãƒ†ãƒ¬æ±",
    "FUJI-TV-TKY": "ãƒ•ã‚¸ãƒ†ãƒ¬ãƒ“", "TOKYO-MX": "TOKYO",
    # é–¢æ± åºƒåŸŸ
    "TVS": "ãƒ†ãƒ¬ç‰", "CTC": "ãƒãƒãƒ†ãƒ¬", "TVK": "tvk",
    # BSç„¡æ–™
    "NHK-BS": "ï¼®ï¼¨ï¼«ã€€ï¼¢ï¼³", "BS-NTV": "BSæ—¥ãƒ†ãƒ¬", "BS-ASAHI": "BSæœæ—¥",
    "BS-TBS": "BS-TBS", "BS-TV-TOKYO": "ï¼¢ï¼³ãƒ†ãƒ¬æ±", "BS-FUJI": "BSãƒ•ã‚¸",
    "BS11": "BS11", "BS12-TWELLV": "BS12", "BS-YOSHIMOTO": "ï¼¢ï¼³ã‚ˆã—ã‚‚ã¨",
    "OUJ-TV-BS": "æ”¾é€å¤§å­¦",
    # BSæœ‰æ–™
    "WOWOW-PRIME-BS": "WOWOWãƒ—", "WOWOW-LIVE-BS": "WOWOWãƒ©ã‚¤ãƒ–",
    "WOWOW-CINEMA-BS": "WOWOWã‚·ãƒãƒ", "WOWOW-PLUS-BS": "WOWOWãƒ—ãƒ©ã‚¹",
    "STAR-CH-BS": "ã‚¹ã‚¿ãƒ¼ï½ƒï½ˆ",
    "JSPORTS-1-BS": "J SPORTS 1", "JSPORTS-2-BS": "J SPORTS 2",
    "JSPORTS-3-BS": "J SPORTS 3", "JSPORTS-4-BS": "J SPORTS 4",
    "GREEN-CH-BS": "ã‚°ãƒªãƒ¼ãƒ³ãƒãƒ£ãƒ³ãƒãƒ«", "ANIMAX-BS": "BSã‚¢ãƒ‹ãƒãƒƒã‚¯ã‚¹",
    "TSURIVISION-BS": "BSé‡£ã‚Šãƒ“ã‚¸ãƒ§ãƒ³", "DISNEY-CH-BS": "ãƒ‡ã‚£ã‚ºãƒ‹ãƒ¼ch",
    "NIHON-EIGA-BS": "æ—¥æœ¬æ˜ ç”»å°‚é–€ch",
    # ãã®ä»–
    "JCOM-BS": "J:COM"
}

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def send_discord_notification(message):
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ Discord Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    print("Discordã¸ã®é€šçŸ¥ã‚’è©¦ã¿ã¾ã™...")
    try:
        response = requests.post(DISCORD_WEBHOOK_URL, json={"content": message}, timeout=15)
        # HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ãŒ2xxï¼ˆæˆåŠŸï¼‰ã§ãªã„å ´åˆã«ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹
        response.raise_for_status()
        print("âœ… Discordã¸ã®é€šçŸ¥ã‚’æ­£å¸¸ã«é€ä¿¡ã—ã¾ã—ãŸã€‚")
    except requests.exceptions.RequestException as e:
        # é€šä¿¡ã‚¨ãƒ©ãƒ¼ã‚„HTTPã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦è©³ç´°ã‚’å‡ºåŠ›
        print(f"âŒ Discordé€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        if e.response is not None:
            print(f" -> Response Status: {e.response.status_code}")
            print(f" -> Response Body: {e.response.text}")

def archive_old_db_records():
    print("\n--- å¤ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–é–‹å§‹ ---")
    cutoff_date_str = (datetime.now() - timedelta(days=ROTATION_DAYS)).strftime('%Y-%m-%d')
    print(f"{cutoff_date_str} ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã—ã¾ã™ã€‚")
    try:
        for table_name in ["programs_epg", "programs"]:
            response = supabase.table(table_name).select("*").lt('broadcast_date', cutoff_date_str).execute()
            if response.data:
                print(f" -> {table_name}: {len(response.data)}ä»¶ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸­...")
                supabase.table(f"{table_name}_archive").upsert(response.data).execute()
                supabase.table(table_name).delete().lt('broadcast_date', cutoff_date_str).execute()
        print("âœ… å¤ã„DBãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Œäº†ã€‚")
    except Exception as e:
        print(f"âŒ DBãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

def archive_old_files():
    print("\n--- å¤ã„JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–é–‹å§‹ ---")
    cutoff_date = datetime.now() - timedelta(days=ROTATION_DAYS)
    os.makedirs(JSON_ARCHIVE_DIR, exist_ok=True)
    try:
        for folder_name in os.listdir(JSON_BACKUP_DIR):
            try:
                folder_date = datetime.strptime(folder_name, '%Y-%m-%d')
                if folder_date < cutoff_date:
                    source_path = os.path.join(JSON_BACKUP_DIR, folder_name)
                    destination_path = os.path.join(JSON_ARCHIVE_DIR, folder_name)
                    if os.path.exists(destination_path): shutil.rmtree(destination_path)
                    shutil.move(source_path, destination_path)
                    print(f"ç§»å‹•ã—ã¾ã—ãŸ: {source_path}")
            except (ValueError, FileNotFoundError): continue
        print("âœ… å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Œäº†ã€‚")
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    print("ğŸš€ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é–‹å§‹ã—ã¾ã™ã€‚")

    # --- 1. EPGåŸºæœ¬æƒ…å ±ã®å–å¾— ---
    epg_data_to_upsert = []
    processed_event_ids = set()
    target_dates = [(datetime.now() + timedelta(days=i)) for i in range(-1, 8)]

    print("\n--- EPGåŸºæœ¬æƒ…å ±ã®å–å¾—é–‹å§‹ ---")
    for ch_type in ["td", "bs"]:
        for target_date in target_dates:
            date_str_url = target_date.strftime("%Y%m%d")
            date_str_db = target_date.strftime("%Y-%m-%d")
            url = f"https://bangumi.org/epg/{ch_type}?broad_cast_date={date_str_url}"
            if ch_type == "td":
                url += "&ggm_group_id=42"

            print(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")
            try:
                res = requests.get(url, timeout=20)
                res.raise_for_status()
                soup = BeautifulSoup(res.text, 'html.parser')
                channel_tags = soup.find_all("li", class_="js_channel topmost")
                channel_names = [tag.text.strip() for tag in channel_tags]
                program_lines = soup.find_all("ul", id=lambda x: x and x.startswith("program_line_"))

                for i, line in enumerate(program_lines):
                    programs = line.find_all("li")
                    for program_tag in programs:
                        a_tag = program_tag.find("a", class_="title_link")
                        if not a_tag:
                            continue

                        href = a_tag.get("href", "")
                        event_id = href.split("/")[-1].split("?")[0]
                        if not event_id or event_id in processed_event_ids:
                            continue

                        channel_name = channel_names[i] if i < len(channel_names) else "ä¸æ˜"
                        channel_code = next(
                            (code for code, name in CHANNEL_MAPPING.items() if name in channel_name), None
                        )

                        epg_data_to_upsert.append({
                            "event_id": event_id,
                            "broadcast_date": date_str_db,
                            "channel": channel_name,
                            "start_time": str(program_tag.get("s", "")),
                            "end_time": str(program_tag.get("e", "")),
                            "program_title": a_tag.find("p", class_="program_title").text.strip(),
                            "program_detail": a_tag.find("p", class_="program_detail").text.strip(),
                            "link": "https://bangumi.org" + href,
                            "region": "æ±äº¬",
                            "channel_code": channel_code
                        })
                        processed_event_ids.add(event_id)
            except Exception as e:
                print(f"  -> EPGãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                continue

    if not epg_data_to_upsert:
        raise Exception("EPGæƒ…å ±ãŒä¸€ä»¶ã‚‚å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")

    print(f"\nâœ… {len(epg_data_to_upsert)}ä»¶ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªEPGæƒ…å ±ã‚’å–å¾—ã€‚DBã«ç™»éŒ²ã—ã¾ã™...")
    supabase.table('programs_epg').upsert(epg_data_to_upsert, on_conflict='event_id').execute()

    # --- 2. ç•ªçµ„è©³ç´°æƒ…å ±ã®å–å¾— ---
    print("\n--- ç•ªçµ„è©³ç´°æƒ…å ±ã®å–å¾—é–‹å§‹ ---")
    program_details_to_upsert = []
    appearances_to_upsert = []
    talents_seen = {}

    for program in epg_data_to_upsert:
        if not program.get('link') or program.get('channel_code') not in TARGET_CHANNELS:
            continue

        print(f"è©³ç´°å–å¾—ä¸­: {program['program_title']}")
        try:
            res_detail = requests.get(program['link'], timeout=20)
            res_detail.raise_for_status()
            soup_detail = BeautifulSoup(res_detail.text, 'html.parser')

            title = program['program_title']
            meta_desc = soup_detail.find("meta", {"name": "description"})
            description = meta_desc["content"].strip() if meta_desc else ""
            letter_body = soup_detail.find("p", class_="letter_body")
            description_detail = letter_body.get_text(strip=True) if letter_body else ""
            genre_tag = soup_detail.find("p", class_="genre nomal")
            genre = genre_tag.get_text(strip=True).replace("\u3000", " ") if genre_tag else ""
            site_tag = soup_detail.select_one("ul.related_link a")
            official_website = site_tag.get("href") if site_tag else ""

            # å‡ºæ¼”è€…ãƒªãƒ³ã‚¯æŠ½å‡º
            performer_links = {}
            for a in soup_detail.select("a[href*='/talents/']"):
                name = a.get_text(strip=True)
                href = a.get("href", "")
                if name and href and not href.rstrip("/").endswith("talents"):
                    performer_links[name] = "https://bangumi.org" + href if href.startswith("/") else href

            talents_to_upsert = []
            for name, link in performer_links.items():
                try:
                    if not name or not link:
                        continue
                    talent_id = link.rstrip("/").split("/")[-1].split("?")[0]
                    if talent_id.isdigit():
                        if talent_id not in talents_seen:
                            talents_to_upsert.append({
                                "talent_id": talent_id,
                                "name": name,
                                "link": link
                            })
                            talents_seen[talent_id] = name
                        appearances_to_upsert.append({
                            "program_event_id": program['event_id'],
                            "talent_id": talent_id
                        })
                except Exception as e:
                    print(f"âš ï¸ ã‚¿ãƒ¬ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {name} - {e}")
                    continue

            if talents_to_upsert:
                supabase.table('talents').upsert(talents_to_upsert, on_conflict='talent_id').execute()

            db_data = {
                "event_id": program['event_id'],
                "broadcast_date": program['broadcast_date'],
                "channel": program['channel'],
                "start_time": program['start_time'],
                "end_time": program['end_time'],
                "master_title": title.split("ã€€")[0] if "ã€€" in title else title,
                "program_title": title,
                "description": description,
                "description_detail": description_detail,
                "genre": genre,
                "official_website": official_website,
                "channel_code": program['channel_code']
            }
            program_details_to_upsert.append(db_data)

            # JSONãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜
            date_str = program['broadcast_date']
            start_hhmm = program['start_time'][8:12] if len(program['start_time']) >= 12 else "0000"
            file_name = f"{date_str}-{start_hhmm}_{program['channel_code']}_{program['event_id']}.json"
            storage_path = f"{date_str}/{program['channel_code']}/{file_name}"
            json_string = json.dumps({**db_data, "performers": talents_to_upsert}, ensure_ascii=False, indent=2)

            try:
                supabase.storage.from_('json-backups').upload(
                    path=storage_path,
                    file=json_string.encode('utf-8'),
                    file_options={"content-type": "application/json;charset=utf-8", "upsert": "true"}
                )
                print(f"  -> JSONä¿å­˜å®Œäº†: {storage_path}")
            except Exception as storage_e:
                print(f"âš ï¸ JSONä¿å­˜å¤±æ•—: {storage_e}")

            time.sleep(random.uniform(1.5, 2.5))
        except Exception as e:
            print(f"âŒ ç•ªçµ„è©³ç´°å–å¾—å¤±æ•—: {program['program_title']} - {e}")
            continue

    if program_details_to_upsert:
        print(f"\nâœ… {len(program_details_to_upsert)}ä»¶ã®è©³ç´°æƒ…å ±ã‚’DBç™»éŒ²ã—ã¾ã™...")
        supabase.table('programs').upsert(program_details_to_upsert, on_conflict='event_id').execute()

    if appearances_to_upsert:
        print(f"âœ… {len(appearances_to_upsert)}ä»¶ã®å‡ºæ¼”æƒ…å ±ã‚’appearancesãƒ†ãƒ¼ãƒ–ãƒ«ã«ç™»éŒ²ã—ã¾ã™...")
        supabase.table('appearances').upsert(appearances_to_upsert, on_conflict=["program_event_id", "talent_id"]).execute()

    print("\nğŸ‰ å…¨ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚")
    return len(epg_data_to_upsert), len(program_details_to_upsert)

        
if __name__ == '__main__':
    # å‡¦ç†å¯¾è±¡ã®æ—¥ä»˜ç¯„å›²ã‚’å…ˆã«å®šç¾©
    start_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    end_date = (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')
    
    try:
        # mainé–¢æ•°ã‹ã‚‰å‡¦ç†ä»¶æ•°ã‚’å—ã‘å–ã‚‹
        epg_count, detail_count = main()
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å‡¦ç†
        # archive_old_files()
        archive_old_db_records()
        
        # æˆåŠŸé€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
        success_message = (
            f"âœ… ç•ªçµ„è¡¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚\n\n"
            f"**å‡¦ç†æœŸé–“**: {start_date} ï½ {end_date}\n"
            f"**ç•ªçµ„æ¦‚è¦**: {epg_count}ä»¶ å–å¾—\n"
            f"**ç•ªçµ„è©³ç´°**: {detail_count}ä»¶ å–å¾—"
        )
        send_discord_notification(success_message)
        

    except Exception as e:
        error_message = f"ğŸš¨ ç•ªçµ„è¡¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\n**ã‚¨ãƒ©ãƒ¼å†…å®¹**:\n```\n{e}\n```"
        print(error_message)
        send_discord_notification(error_message)
