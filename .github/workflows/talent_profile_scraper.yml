# .github/workflows/talent_profile_scraper.yml

name: Talent Profile Scraper

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'Execution mode'
        required: true
        default: 'batch'
        type: choice
        options:
          - test
          - batch
          - full
      offset:
        description: 'Starting offset'
        required: false
        default: '0'
        type: string
      
  schedule:
    - cron: '0 19 * * 0'  # Every Sunday at 4 AM JST

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
  DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}

jobs:
  scrape-profiles:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Python environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 supabase python-dotenv
    
    - name: Execute talent profile scraper
      run: |
        MODE="${{ github.event.inputs.mode || 'batch' }}"
        OFFSET="${{ github.event.inputs.offset || '0' }}"
        
        echo "ðŸš€ Starting execution: Mode=$MODE, Offset=$OFFSET"
        python talent_profile_scraper.py --mode $MODE --offset $OFFSET
    
    - name: Upload execution results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraping-results-${{ github.run_number }}
        path: |
          talent_scraping_errors_*.json
        retention-days: 30
